#!/bin/bash
# vmstat 3 -- to monitor swap usage
pushd `dirname $0` >/dev/null 2>/dev/null

#
# Global Environment for --8
#
# export GDCA_IPADDRESS=the ip of this gdca host
# export DBHOST=the ip of the db

#
# Global environments
export GDCA_DOCKER_DNS="--add-host gdca.io:140.92.24.63"
export GDCA_DOCKER_EXTRA=
export BROKER_IP=140.92.24.63


RACC="BigEDA@bigsftp"
RBASE="/home/BigEDA/gdca/g2"
RHOST="${RACC}:${RBASE}"
RUPLOADS="${RACC}:/home/BigEDA/gdca/uploads"
BRINGUP_DELAY=2
GDCA_ON_DUTY=.gdca_on
#DBHOST=140.110.30.126:1433
DBHOST=124.9.14.103:1433
DBPASS=p@ssw0rdP@ssw0rd

# Note: After changing the broker, remember to change gafka's mk.sh
CONFIG_URL=http://gdca.io:3721/config
ETCD_URL=http://gdca.io:3721/etcd
BROKER_URL=gdca.io:3927
#SFTP_URL="BigEDA@140.92.88.120"
SFTP_URL="BigEDA@124.9.14.7"
SITE=--0
SCANGAP=60
PURGE_DAYS=14
UP_USERHOST=""
UP_PASSWORD=""
UP_BASEDIR=""
SCANNER_BACKWARDS=14
SCANNER_DBG_BACKWARDS=$((365*3))
SCANNER_QUOTA_INC=10
SCANNER_QUOTA=$((1024*1024*1024))

#[ "debug.in", "ICOS", "DXF", "OS", "RMS", "MAPPINGTABLE" ]

cat << EOF > yy.scandir.json
[ "debug.in", "MAPPINGTABLE", "STRIP"]
EOF


sendkey() {
	curl -Ls ${CONFIG_URL}/$*
}

putconfig(){
	# $1, key
	# $2, value
	# $3, ttl
	sendkey $1 -d "value=$2" -dttl=$3 -XPUT
}

fputconfig(){
	# $1, key
	# $2, file
	# $3, ttl
	sendkey $1 -dttl=$3 --data-urlencode value@$2 -XPUT
}


config_init(){
	if [ x${CONFIG_URL} = x ]; then
		echo "!! No CONFIG_URL for initialization"
		exit
	fi
	putconfig gdb_tx_print True
	putconfig gdb_ost_out False
	putconfig gdb_use_etcd True
	putconfig etcd ${ETCD_URL}
	putconfig broker ${BROKER_URL}
	putconfig watch.userhost ${SFTP_URL}
	putconfig watch.passwd "BigEDA"
	putconfig watch.directory "/home/BigEDA/"
	putconfig store.directory "/var/gdca/stor"
	putconfig store.chunk.size "1000000"
	putconfig store.chunk.rows "10000"
	putconfig plain.icos.maxbytes "1024000"
	putconfig plain.icos.maxlines "1024"
	putconfig work.life "259200"
	putconfig housekeeper.timeout ""
	putconfig upload.userhost $UP_USERHOST
	putconfig upload.passwd $UP_PASSWORD
	putconfig upload.base.directory $UP_BASEDIR
	putconfig scanner.gap ${SCANGAP}
	putconfig scanner.backs ${SCANNER_BACKWARDS}
	putconfig scanner.dbg.backs ${SCANNER_DBG_BACKWARDS}
	putconfig scanner.quota ${SCANNER_QUOTA}
	putconfig scanner.quota.inc ${SCANNER_QUOTA_INC}
	#fputconfig content.map yy.content.json
	fputconfig scanner.dirs yy.scandir.json
}

do_adjust_sql_ip() {
	# $1 the filename for input
	# $2 the filename for output
	# $3 the ip:port to replace
	# $4 the password to replace
	cat $1 | sed 's/sqlserver:\/\/.*;DatabaseName/sqlserver:\/\/'$3';DatabaseName/g' > y1.tmp
	cat y1.tmp | sed 's/password: .*$/password: '$4'/g' > y2.tmp
	mv y2.tmp $2
}


do_down(){
	docker ps -a --no-trunc | grep "\(/opt/gdca/entry\|/opt/postsql\|/opt/fawor\|/opt/sqldb\|/opt/relmer\)" | awk '{system("docker stop " $1 " &")}'
	for((;;)); do
		cnt=`docker ps -a --no-trunc | grep "\(/opt/gdca/entry\|/opt/postsql\|/opt/fawor\|/opt/sqldb\|/opt/relmer\)" | wc -l` #awk '{system("docker stop " $1 " &")}'
		if(($cnt <= 1)); then
			return
		fi
		sleep 4
	done
}

cleanup(){
	do_down
	if [ -d /var/gdca/log ]; then
		rm -r /var/gdca/log/*log 2>/dev/null
	fi
}

do_fetch(){
	scp ${RHOST}/wk.sh .

	LST=( "gcbox" "tools" "pcbox" "jcbox" "sqlscripts" "sqldbwriter" "faworker" "relmerger" "postsql" )
	for s in "${LST[@]}"; do
		TGT=$s
		scp -r ${RHOST}/${TGT} .
	done
}

do_fetch_srv(){
	LST=( "gafka" "nginx" )
	for s in "${LST[@]}"; do
		TGT=$s
		scp -r ${RHOST}/${TGT} .
	done
}

do_fetch_sql(){
	LST=( "sqldbwriter" "postsql" )
	for s in "${LST[@]}"; do
		TGT=$s
		rm -rf ${TGT}/${TGT} 2>/dev/null
		mkdir ${TGT}/${TGT}
		scp -r ${RUPLOADS}/${TGT} ${TGT}
	done
}

do_fetch_calc(){
	LST=( "sqldbwriter" )
	for s in "${LST[@]}"; do
		TGT=$s
		rm -rf ${TGT}/${TGT} 2>/dev/null
		mkdir ${TGT}/${TGT}
		scp -r ${RUPLOADS}/${TGT} ${TGT}
	done
}

do_fetch_apps(){
	LST=( "pcbox" "jcbox" )
	for s in "${LST[@]}"; do
		TGT=$s
		scp -r ${RUPLOADS}/${TGT} .
	done
	
	LST=( "sqldbwriter" "faworker" "relmerger" "postsql" )
	for s in "${LST[@]}"; do
		TGT=$s
		rm -rf ${TGT}/${TGT} 2>/dev/null
		mkdir ${TGT}/${TGT}
		scp -r ${RUPLOADS}/${TGT} ${TGT}
	done
}

fetch_base(){
	LST=( "basego" "baseka" "basezk" "baseng" "basejav" "basepy")
	for s in "${LST[@]}"; do
		TGT=$s
		scp -r ${RHOST}/${TGT} .
	done
}

make_base(){
	LST=( "baseka" "basezk" "baseng" "basejav" "basepy" "basego" )
	for s in "${LST[@]}"; do
		pushd $s
		bash mk.sh 2>/dev/null
		popd
	done
}

save_base(){
	LST=( "baseka" "basezk" "baseng" "basejav" "basepy" "basego" )
	mkdir ./repo
	pushd repo
	for s in "${LST[@]}"; do
		docker image save gdca/$s | gzip -c - > $s.tgz
	done
	popd
}

load_base(){
	LST=( "baseka" "basezk" "baseng" "basejav" "basepy" "basego" )
	pushd repo
	for s in "${LST[@]}"; do
		zcat $s.tgz | docker image load
	done
	popd
}

do_build(){
	LST=( "pcbox" "jcbox" "sqldbwriter" "faworker" "relmerger" "postsql" )
	for s in "${LST[@]}"; do
		pushd $s
		bash mk.sh ${SITE} 2>/dev/null
		popd
	done
}


do_build_sql(){
	LST=( "sqldbwriter" "postsql" )
	for s in "${LST[@]}"; do
		pushd $s
		bash mk.sh ${SITE} 2>/dev/null
		popd
	done
}

do_up(){
	LST=( "scanner" "genprep")
	pushd jcbox
	echo entering `pwd`
	for s in "${LST[@]}"; do
		bash -x run.sh ${SITE} --etcd ${CONFIG_URL} --docker $s
		sleep ${BRINGUP_DELAY}
	done
	popd
	echo back to `pwd`

	pushd pcbox
	echo entering `pwd`
	LST=( "ost" "osd" "dxf" "ict" "icd" "iqa" "region" "strip" "plat" )
	for s in "${LST[@]}"; do
		bash -x run.sh ${SITE} --etcd ${CONFIG_URL} $s
		sleep ${BRINGUP_DELAY}
	done
	popd
	echo back to `pwd`

	LST=( "sqldbwriter" "faworker" "relmerger" "postsql" )
	#LST=( "sqldbwriter" "sqldbwriter" "sqldbwriter" "sqldbwriter" )
	for s in "${LST[@]}"; do
		pushd $s
		echo entering `pwd`
		bash -x run.sh ${SITE} --etcd ${CONFIG_URL} $s
		sleep ${BRINGUP_DELAY}
		popd
		echo back to `pwd`
	done
}

do_poll_kafka(){
	pth=/g2/gafka
	pat=start-kafka
	echo poll ${pat} at `date`
	cnt=`docker ps -a --no-trunc | grep ${pat} | grep Restarting | wc -l`
	if [[ $cnt == 0 ]]; then
		echo ${pat} is running
		return
	else
		pushd ${pth}
		bash mk.sh ${SITE} down
		sleep 30
		bash mk.sh ${SITE} "up -d"
		popd
	fi	
}

do_poll_box(){
	# $1, the application directoy, e.g. jcbox or pcbox
	# $2, the target to run
	pat=$2
	cnt=`docker ps -a --no-trunc | grep "gdca/entry.sh ${pat}" | wc -l`
	if [[ $cnt > 0 ]]; then
		#echo ${pat} is running
		return
	else
		cd $1
		bash -x run.sh ${SITE} --etcd ${CONFIG_URL} ${pat}
		cd ..
		sleep ${BRINGUP_DELAY}
	fi	
}

do_poll_ext(){
	# $1, the application directoy, meanwhile the target, e.g. sqldbwriter
	pat=$1
	cnt=`docker ps -a --no-trunc | grep "${pat}/custom.sh" | wc -l`
	if [[ $cnt > 0 ]]; then
		#echo ${pat} is running
		return
	else
		cd $1
		bash -x run.sh ${SITE} --etcd ${CONFIG_URL} ${pat}
		cd ..
		sleep ${BRINGUP_DELAY}
	fi	
}

do_poll() {
	if [ ! -f ${GDCA_ON_DUTY} ]; then
		return
	fi
	do_poll_kafka
	echo poll task starts at `date`
	do_poll_box jcbox scanner
	do_poll_box jcbox genprep
	do_poll_box pcbox ost
	do_poll_box pcbox osd
	do_poll_box pcbox ict
	do_poll_box pcbox icd
	do_poll_box pcbox iqa
	do_poll_box pcbox region
	do_poll_box pcbox plat
	do_poll_box pcbox strip
	do_poll_box pcbox dxf
	do_poll_ext sqldbwriter
	do_poll_ext faworker
	do_poll_ext relmerger
	do_poll_ext postsql
	return
}

do_purge() {
	# $1, the days before to purge in /var/gdca/stor
	cur=`date +%s`
	pgdate=$((cur - 86400*$1))
	echo purge task starts at `date`
	echo purge date before `date --date=@${pgdate} +%F`
	for d in /var/gdca/stor/* ; do
		mdate=`stat -c%Y $d`
		#echo $d=`stat -c%y $d` - $mdate 
		if [[ $pgdate < $mdate ]]; then
			continue
		fi
		echo purge directory $d
		rm -rf $d
	done
}

for((;$# > 0;)); do
	arg=$1
	shift
	if [ $arg == --config.init ]; then
		config_init
		continue
	fi
	if [ $arg == --dwg.config.init ]; then
		CONFIG_URL=${CONFIG_URL}.dwg
		UP_USERHOST="BigEDA@124.9.14.7"
		UP_PASSWORD="BigEDA"
		UP_BASEDIR="/home/BigEDA/"
		config_init
		continue
	fi
	if [ $arg == --make-base ]; then
		make_base
		continue
	fi
	if [ $arg == --fetch-base ]; then
		fetch_base
		continue
	fi
	if [ $arg == --save-base ]; then
		save_base
		continue
	fi
	if [ $arg == --load-base ]; then
		load_base
		continue
	fi
	if [ $arg == --build ]; then
		do_build
		continue
	fi
	if [ $arg == --rebuild ]; then
		do_fetch
		do_fetch_apps
		do_build
		continue
	fi
	if [ $arg == --rebuild-sql ]; then
		do_fetch_sql
		do_build_sql
		continue
	fi
	if [ $arg == --up ]; then
		touch ${GDCA_ON_DUTY}
		do_poll
		continue
	fi
	if [ $arg == --down ]; then
		rm -rf ${GDCA_ON_DUTY}
		do_down
		continue
	fi
	if [ $arg == --clean ]; then
		cleanup
		continue
	fi
	if [ $arg == --poll ]; then
		do_poll
		continue
	fi
	if [ $arg == --poll-kafka ]; then
		do_poll_kafka
		continue
	fi
	if [ $arg == --purge ]; then
		do_purge $PURGE_DAYS
		continue
	fi
	if [ $arg == --delay ]; then
		BRINGUP_DELAY=$1
		shift
		continue
	fi
	if [ $arg == --etcd ]; then
		CONFIG_URL=$1
		shift
		continue
	fi
	if [ $arg == --mkdir ]; then
		LST=( "tools" "basego"  "basejav" "basepy" "baseka" "basezk" "baseng" "nginx" "gafka" "jcbox" "pcbox" "sqldbwriter" "faworker" "relmerger" "postsql" )
		for s in "${LST[@]}"; do
			mkdir $s 2>/dev/null
		done
		continue
	fi
	if [ $arg == -e ]; then
		eval "export $1=$2"
		shift
		shift
		continue
	fi
	if [ $arg == --show-exports ]; then
		echo GDCA_IPADDRESS=$GDCA_IPADDRESS
		echo GDCA_DOCKER_DNS=$GDCA_DOCKER_DNS
		echo SFTP_URL=$SFTP_URL
		echo DBHOST=$DBHOST
		echo DBPASS=$DBPASS
		continue
	fi
	if [ $arg == --exit ]; then
		set | grep GD
		exit
	fi
	if [ $arg == --0 ]; then
		SITE=--0
		export GDCA_DOCKER_DNS="--add-host gdca.io:140.92.24.63"
		continue
	fi
	if [ $arg == --1 ]; then
		SITE=--1
		export GDCA_DOCKER_DNS=
		export BROKER_IP=10.10.28.89
		CONFIG_URL=http://10.10.28.89:3721/config
		ETCD_URL=http://10.10.28.89:3721/etcd
		BROKER_URL=10.10.28.89:3927
		SFTP_URL="BigEDA@10.10.28.89"
		SCANGAP=1800
		SCANNER_BACKWARDS=14
		SCANNER_DBG_BACKWARDS=$((365*3))
		SCANNER_QUOTA_INC=50000
		SCANNER_QUOTA=$((1024*1024*1024*2))
		cat << EOF > yy.scandir.json
[ "debug.in", "ICOS", "DXF", "OS", "RELIABILITY", "ERA", "GUI_IQA_XLS", "RMS", "MAPPINGTABLE", "STRIP" ]
EOF
		continue
	fi
	if [ $arg == --2 ]; then
		SITE=--2
		export GDCA_DOCKER_DNS=
		export BROKER_IP=10.10.28.91
		CONFIG_URL=http://10.10.28.91:3721/config
		ETCD_URL=http://10.10.28.91:3721/etcd
		BROKER_URL=10.10.28.91:3927
		SFTP_URL="BigEDA@10.10.28.91"
		SCANGAP=1800
		SCANNER_BACKWARDS=14
		SCANNER_DBG_BACKWARDS=$((365*3))
		SCANNER_QUOTA_INC=50000
		SCANNER_QUOTA=$((1024*1024*1024*2))
		cat << EOF > yy.scandir.json
[ "debug.in", "ICOS", "DXF", "OS", "RELIABILITY", "ERA", "GUI_IQA_XLS", "RMS", "MAPPINGTABLE", "STRIP" ]
EOF
	continue
	fi
	if [ $arg == --8 ]; then
		if [ x${GDCA_IPADDRESS} = x ]; then
			echo Please export GDCA_IPADDRESS
			exit
		fi
		SITE=--0
		export GDCA_DOCKER_DNS="--add-host gdca.io:"$GDCA_IPADDRESS
		export BROKER_IP=$GDCA_IPADDRESS
		SFTP_URL="BigEDA@124.9.14.7"
		SCANGAP=1800
		SCANNER_BACKWARDS=14
		SCANNER_DBG_BACKWARDS=$((365*3))
		SCANNER_QUOTA_INC=50000
		SCANNER_QUOTA=$((1024*1024*1024*2))
		cat << EOF > yy.scandir.json
[ "debug.in", "MAPPINGTABLE", "STRIP" ]
EOF
		do_adjust_sql_ip /g2/sqldbwriter/sqldbwriter/setting/application.yml /g2/sqldbwriter/sqldbwriter/setting/application.yml $DBHOST $DBPASS
		do_adjust_sql_ip /g2/postsql/postsql/setting/application.yml /g2/postsql/postsql/setting/application.yml $DBHOST $DBPASS
		continue
	fi
	if [ $arg == --9 ]; then
		RACC="kk@kkio.io"
		RBASE="/home/kk/g2"
		RHOST="${RACC}:${RBASE}"
		RUPLOADS="${RACC}:/home/uploads"
		SITE=--9
		CONFIG_URL=http://kkio.io:3721/config
		ETCD_URL=http://kkio.io:3721/etcd
		BROKER_URL=kkio.io:3927
		continue
	fi
	if [ $arg == --fetch ]; then
		do_fetch
		continue
	fi
	if [ $arg == --fetch-srv ]; then
		do_fetch_srv
		continue
	fi
	if [ $arg == --fetch-apps ]; then
		do_fetch_apps
		continue
	fi
	if [ $arg == --fetch-me ] || [ $arg == --me ] ; then
		scp ${RHOST}/deploy.sh .
		break
	fi
	
	echo "!!unknown command $arg"
	break
done
popd >/dev/null 2>/dev/null
